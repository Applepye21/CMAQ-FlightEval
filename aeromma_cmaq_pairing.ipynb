{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9889093b-7953-4008-b6ff-c00093ab166c",
   "metadata": {},
   "source": [
    "# AREOMMA NASA DC-8 Aircraft Data to CMAQ Pairing\n",
    "\n",
    "---\n",
    "    author: Michael J. Pye (pye.michael@epa.gov)\n",
    "    date created: 2025-01-10\n",
    "---\n",
    "\n",
    "### Origin\n",
    "This notebook is based upon another notebook written by Havala Pye (pye.havala@epa.gov) for the FIREX field campaign created on 2023-01-10.  \n",
    "The path to the original notebook is: /work/MOD3DEV/has/2022firex/postproc/notebooks/2024_firexpairv3_hotp_20240304_base3.ipynb  \n",
    "Although this notebook has a very different structure, at least some of the ideas for this notebook came from that notebook. \n",
    "\n",
    "### Purpose\n",
    "This notebook is designed to perform flight pairing tasks specific to the AEROMMA aircraft observations. \n",
    "\n",
    "### Log\n",
    "* 01/10/2025 - added an import of scipy to the check install version cell\n",
    "* 01/10/2025 - added section to read in merge.csv files as opposed to icartt files\n",
    "* 01/13/2025 - started the file fresh. Revoved all code and rearranged the introduction section\n",
    "* 01/13/2025 - added `find_one_minute_coords()`, a function that finds x, y, p, and t from any AEROMMA flight and aggregates the data from a one second time step to a one minute time step.\n",
    "* 01/13/2025 - added `flight_id_creator()`, a function that creates a flight ID based on the name of the AEROMMA merge file\n",
    "* 01/16/2025 - updated the `find_one_minute_coords()` function to remove all one second observations missing at least one coordinate value\n",
    "* 01/17/2025 - split the `find_one_minute_coords()` function into two sepearate functions; one to find coordinates based on the input merge file to address the fact that some files have different coordinate data sets, and another to aggregate the one second data into one minute time steps.\n",
    "* 01/21/2025 - addressed issues in the function for aggregating one second data to one minute time steps.\n",
    "* 01/30/2025 - added a function to compare coordinate data in CMAQ and from AEROMMA to see how well they line up.\n",
    "* 01/30/2025 - added a function to plot paired AEROMMA and CMAQ data of the same variable to look for outliers in the matches.\n",
    "* 02/03/2025 - Added a function to extract flight data in addition to just the coordinate data\n",
    "* 02/04/2025 - Added a function that prints a list of variables in an AEROMMA merge file based on the path of the merge file\n",
    "* 02/07/2025 - Added a function that removes time steps from both AEROMMA and CMAQ DataFrames for times when the aircraft is outside the model domain\n",
    "* 02/07/2025 - Replaced the `one_minute_data()` function with the `time_agg_data()` function. The function works the same way except the `time_agg_data()` allows for multiple time interval options as opposed to just one minute.\n",
    "* 02/07/2025 - added a function to remove negative values from columns that should not have them.\n",
    "* 03/11/2025 - Began writing a function to consolidate a fully cleaned flight DataFrame (CMAQ or AEROMMA) into a DataFrame where each row represents an altitude bin.\n",
    "* 03/24/2025 - Completed a function that plots the variation of data in the vertical\n",
    "* 03/28/2025 - Added a function to remove CMAQ data for times when AEROMMA data is missing. This only operates on a single column of data as opposed to an entire DataFrame.\n",
    "* 04/02/2025 - Added a function to plot the spatial variation of differences between CMAQ and AEROMMA data.\n",
    "* 04/04/2025 - Added a function to plot time series of CMAQ and/or AEROMMA data.\n",
    "* 04/07/2025 - Added a funtion that produces a table of statistics to compare CMAQ and AEROMMA data\n",
    "* 04/10/2025 - Added a function to create a scatter plot of any variable as a function of hydrogen cyanide concentration. Hydrogen cyanide is common in wildfire smoke, which means plotting other variables as a function of HCN could help isolate if CMAQ is performing well or not in wildfire smoke plumes.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3a3dcc-c69a-450d-9fbb-6576f8fb3564",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96455df8-a227-46b6-8c54-533ba58772ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plot\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib import gridspec\n",
    "from warnings import warn\n",
    "import scipy.stats as sp_stat\n",
    "\n",
    "#Import Jupyter Notebooks\n",
    "import import_ipynb\n",
    "import cmaq_flight_pairing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e55cd4d-202f-45d8-a034-beb9633a5aa3",
   "metadata": {},
   "source": [
    "# Prepare AEROMMA data for pairing\n",
    "### Find flight coordinates\n",
    "The `find_coords()` function opens an AEROMMA Merge file and exctracts the coordinate data. The coordinates extracted are:  \n",
    "* GPS Longitude [Degrees] (Converted from degrees * 10^5.)\n",
    "* GPS Latitude [Degrees] (Converted from degrees * 10^5)\n",
    "* GPS Altitude Above Sea Level [meters] (Converted from decimeters)\n",
    "* Time [Format: YYYY-MM-DD HH:MM:SS]  \n",
    "\n",
    "Parameters:\n",
    "* `mrg_file_path` (str) - The path of the AEROMMA merge file for the desired flight. Can be a relative or absolute path, but absolute is recommended. \n",
    "\n",
    "Returns:  \n",
    "* `coord_df` (pandas.Dataframe) - DataFrame that stores the coordinate data under keys: `'G_LONG'`, `'G_LAT'`, and `'G_ALT'`. Each row in the dataframe is indexed by the time stamp of the AEROMMA observation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f544d-1708-48b3-b7b6-15352353c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_coords(mrg_file_path):\n",
    "    #open merge file and #extract coordinate data\n",
    "    mrg_data = pd.read_csv(mrg_file_path)\n",
    "    sec_times = mrg_data['Time'].values   #times have a format of YYYY-MM-DD HH:MM:SS and are in string format\n",
    "    sec_lons = mrg_data['G_LONG'].values / (10 ** 5)   #values are positive in the eastern hemisphere and negative in the western hemisphere. values are stored after having been multiplied by 10^5\n",
    "    sec_lats = mrg_data['G_LAT'].values / (10 ** 5)   #values are positive in the northern hemisphere and negative in the southern hemisphere. values are stored after having been multiplied by 10^5\n",
    "    sec_alts = mrg_data['G_ALT'].values * 0.1    #values are originally in units of decimeters and represent height above sea level. They are then converted to meters by multiplying by 0.1 m/dm   \n",
    "    coord_df = pd.DataFrame({'G_LONG':sec_lons, 'G_LAT':sec_lats, 'G_ALT':sec_alts, 'Time':sec_times})\n",
    "    return coord_df.set_index('Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f98d40c-b38c-418c-a2fc-e7f50def2530",
   "metadata": {},
   "source": [
    "### Aggregate to user defined timestep\n",
    "The purpose of the `time_agg_data()` function is to take a pandas DataFrame with data at a one second time step, that includes the keys `'Time'`, `'G_LONG'`, `'G_LAT'`, and `'G_ALT'`, and converts it to have a time step of a desired length.  \n",
    "\n",
    "Parameters:\n",
    "* `flight_df` (pandas.DataFrame) - DataFrame containing at least flight coordinate data and with a time step of less than a minute. The index must be the time stamp of each observation. \n",
    "* `agg_timestep` (int) [Default: `60`] - number of minutes or seconds for each aggregated time interval. This must be a factor of 60. Possible options are: 1, 2, 3, 4, 5, 6, 10, 12, 15, 30, and 60. Any other value will raise a `ValueError`.\n",
    "* `time_units` (str) [Default: `'sec'`] - units of the aggregated time step. possible options are `'sec'` (for seconds) and `'min'` (for minutes)\n",
    "  \n",
    "Returns:\n",
    "* `agg_df` (pandas.DataFrame) - DataFrame that contains the same data as the input DataFrame but aggregated to a user defined time step and with the index based on the `'Time'` merge variable. The coordinate data is always present for all rows of the output DataFrame. When a variable has no data for a given timestep, the value for that time is marked with numpy.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1e77e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_agg_data(flight_df, agg_timestep = 60, time_units = 'sec'):\n",
    "    if agg_timestep in [1, 2, 3, 4, 5, 6, 10, 12, 15, 20, 30, 60]:    #make sure agg_timestep is always a factor of 60\n",
    "        col_keys = flight_df.keys()\n",
    "        ob_ct = {}    #keeps track of the number of observations for each individual variable during one aggregation timestep\n",
    "        agg_data = {}    #stores arrays of aggregated data for all variables\n",
    "        agg_data['Time'] = []\n",
    "        for key in col_keys:\n",
    "            agg_data[key] = [0]\n",
    "            ob_ct[key] = 0\n",
    "\n",
    "        #iterate through all observations\n",
    "        for i in range(len(flight_df['G_LAT'].values)):\n",
    "            missing_coord_check = [pd.isnull(coord) for coord in [flight_df['G_LONG'].values[i], flight_df['G_LAT'].values[i], flight_df['G_ALT'].values[i]]]\n",
    "            if True not in missing_coord_check:\n",
    "                current_round_time = round_time(flight_df.index[i], agg_timestep, time_units)    #see the explination for the round_time() function below\n",
    "                if 'last_round_time' not in locals():\n",
    "                    last_round_time = round_time(flight_df.index[i], agg_timestep, time_units)    #see the explination for the round_time() function below\n",
    "\n",
    "                #if the round time has not changed since the previous observation, add current values to the timestep total\n",
    "                if current_round_time == last_round_time:\n",
    "                    for key in col_keys:\n",
    "                        try:\n",
    "                            current_value = np.array(flight_df[key])[i]\n",
    "                            int(current_value)    #if the current value is a nan value, this line will cause a ValueError to be raised. This will prevent the missing data from being added to the agg_data array and will stop an additional count from occuring in the ob_ct dict for the variable\n",
    "                            agg_data[key][-1] += current_value\n",
    "                            ob_ct[key] += 1\n",
    "                        except ValueError:\n",
    "                            pass\n",
    "\n",
    "                #if the round_time has changed since the previous observation, divide the sum of the values by the number\n",
    "                #of observations taken that timestep, then add the current values to a new runing total\n",
    "                elif current_round_time != last_round_time:\n",
    "                    agg_data['Time'].append(last_round_time)\n",
    "                    for key in col_keys:\n",
    "                        if ob_ct[key] > 0:    #if values exist for the timestep, take the average of those values\n",
    "                            agg_data[key][-1] /= ob_ct[key]\n",
    "                        else:    #if values do not exist for the timestep, set the value of the for the timestep to np.nan\n",
    "                            agg_data[key][-1] = np.nan\n",
    "                    for key in col_keys:    #prep lists for new data and add first data point of the timestep\n",
    "                        agg_data[key].append(0)\n",
    "                        ob_ct[key] = 0\n",
    "                        try:\n",
    "                            current_value = np.array(flight_df[key])[i]\n",
    "                            int(current_value)\n",
    "                            agg_data[key][-1] += current_value\n",
    "                            ob_ct[key] += 1\n",
    "                        except ValueError:\n",
    "                            pass\n",
    "\n",
    "                last_round_time = current_round_time \n",
    "\n",
    "        #determine if there is any data left over that needs to be included and averaged\n",
    "        present_data = False\n",
    "        for key in col_keys:\n",
    "            if ob_ct[key] != 0:\n",
    "                present_data = True\n",
    "        \n",
    "        #take the average of remaining data is there is any.\n",
    "        if present_data == True:\n",
    "            agg_data['Time'].append(last_round_time)\n",
    "            for key in col_keys:\n",
    "                if ob_ct[key] > 0:    #if values exist for the timestep, take the average of those values\n",
    "                    agg_data[key][-1] /= ob_ct[key]\n",
    "                else:    #if values do not exist for the timestep, set the value of the for the timestep to np.nan\n",
    "                    agg_data[key][-1] = np.nan\n",
    "\n",
    "        agg_df = pd.DataFrame(agg_data).set_index('Time')\n",
    "        return agg_df\n",
    "    \n",
    "    #if agg_timestep is not a factor of 60, raise a ValueError to prevent further issues\n",
    "    else:\n",
    "        raise ValueError('AEROMMA Flight Pairing: The value entered for \"agg_timestep\" is not a factor of 60.')\n",
    "\n",
    "\n",
    "###Extra function for use in time_agg_data()\n",
    "#this function creates a string that rounds the time down to the closest time data is getting aggregated to.\n",
    "#For example, if the time_str contains 19:25:39, the agg_timestep is 20, and the time units is \"sec\", the \n",
    "#out_time would contain 19:25:20. This would aggregate the data from 19:25:39 to the 19:25:20 timestep. If \n",
    "#the time was changed to 19:45:43, out_time would be 19:45:40. If the time_units parameter was changed to \n",
    "#\"min\", the out_time values for the same times would be 19:20:00 and 19:40:00.\n",
    "def round_time(time_str, agg_timestep, time_units):\n",
    "    if time_units == 'min':\n",
    "        min_value = int(time_str[-5:-3])    #number of minutes past the hour\n",
    "        min_factor = int(min_value / agg_timestep)\n",
    "        out_time = datetime.datetime.strptime(time_str[:-6], '%Y-%m-%d %H') + (datetime.timedelta(minutes = agg_timestep) * min_factor)\n",
    "    elif time_units == 'sec':\n",
    "        sec_value = int(time_str[-2:])     #number of seconds past the minute \n",
    "        sec_factor = int(sec_value / agg_timestep)\n",
    "        out_time = datetime.datetime.strptime(time_str[:-3], '%Y-%m-%d %H:%M') + (datetime.timedelta(seconds = agg_timestep) * sec_factor)\n",
    "    return out_time.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f05f3bb-745a-46b7-8d21-add01e9369df",
   "metadata": {},
   "source": [
    "### Create a unique ID for the flight\n",
    "The purpose of the `flight_id_creator()` function is to create a string ID that is unique to the flight so it can be added as the name of a netcdf variable. It can also be used to find what a flight ID within an already generated netCDF should be based on the flight name. It takes the path of the merge file and strips the flight_specific information from the file name and creates an ID based on that.  \n",
    "  \n",
    "Parameters:  \n",
    "* `mrg_file_path` (str) - The path of the AEROMMA merge file for the desired flight. Can be a relative or absolute path, but absolute is recommended.  \n",
    "  \n",
    "Returns:\n",
    "* `flight_id` (str) - The flight ID. This can be used to give to a NetCDF file to create a variable name, or to replicate what the NetCDF likely has stored as the variable for the flight at hand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca3dccc-d2fb-443d-936d-dec9a75f7663",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flight_id_creator(mrg_file_path):\n",
    "    #Get Merge file name and remove all parts of the file name not specific to the flight\n",
    "    mrg_file_name = os.path.basename(mrg_file_path)\n",
    "    split = mrg_file_name.split('_')\n",
    "    split.remove('AEROMMA')\n",
    "    split.remove('Merge.csv')\n",
    "    \n",
    "    #Create the flight ID based on the remaining parts of the Merge file name\n",
    "    if len(split) == 1:\n",
    "        flight_id = 'flight_' + split[0]    #This is specific to when there is exactly one flight in a day\n",
    "    elif len(split) == 2:\n",
    "        flight_id = 'flight_' + split[0] + '_' + split[1]    #This is specific to when there are exactly two flights in a day\n",
    "    return flight_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4765600f-401e-4d25-a2ee-56f4e638a099",
   "metadata": {},
   "source": [
    "### Pair AEROMMA data to CMAQ\n",
    "The purpose of the `pair_aeromma_flight()` function is to add the CMAQ indices associated with an AEROMMA flight trajectory to a netCDF file based on the path of the AEROMMA merge file, the path of the netCDF file, and the directory storing the CMAQ data.  \n",
    "\n",
    "Parameters:\n",
    "* `mrg_file_path` (str) - path to the AEROMMA merge file\n",
    "* `index_file_path` (str or NoneType) - path to the netCDF file where the indices are to be stored. If the file does not exist yet, enter `None`.\n",
    "* `domain_dir` (str) - The absolute path of the directory where the GRIDCRO2D and METCRO3D are stored. \n",
    "* `model_resolution` (int) [Default: `12000`] - The horizontal grid spacing of the model in units of meters. This is only used to tell the function if the aircraft has left the model domain. Set this value to limit the farthest distance from a model grid point that you would like flight data to pair to model data. \n",
    "* `alt_type` (str) [Default: `'ASL'`] - specifies whether the altitudes passed to the function are in height above ground level or height above sea level. the options are `'ASL'` (above sea level) and `'AGL'` (above ground level) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa0134e-f462-48cd-a929-4418f2537699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_aeromma_flight(mrg_file_path, index_file_path, domain_dir, model_resolution = 12000, alt_type = 'AGL'):\n",
    "    sec_coords = find_coords(mrg_file_path)\n",
    "    min_coords = time_agg_data(sec_coords)\n",
    "    flight_id = flight_id_creator(mrg_file_path)\n",
    "    cmaq_flight_pairing.pair_flight(flight_id, min_coords['G_LONG'], min_coords['G_LAT'], min_coords['G_ALT'], min_coords.index, index_file_path, domain_dir, model_resolution = model_resolution, alt_type = alt_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2297c35e-3a75-4509-a76c-b14b00a778de",
   "metadata": {},
   "source": [
    "The purpose of the `pair_all_aeromma_flights()` function is to perform the actions of the `pair_aeromma_flight()` function for all AEROMMA merge files within a directory.  \n",
    "\n",
    "Parameters:  \n",
    "* `mrg_dir_path` (str) - Path of the directory containing multiple AEROMMA Merge files or multiple directries that contain a Merge file. If the Merge files are in sub-directories of the mrg_dir_path, the Merge file name must be the same as the sub-directory name but with a `.csv` at the end. For example: `mrg_dir_path/AEROMMA_20230614_Merge/AEROMMA_20230614_Merge.csv`.\n",
    "* `index_file_path` (str) - Path to the netCDF file where the indices are to be stored.\n",
    "* `sub_directory` (bool) [Default: `True`] - Tells the function whether the Merge files are directly in the `mrg_dir_path` directory or in sub-directories of the `mrg_dir_path` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e961d7a9-f4bf-4f5f-a817-9dce2208790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_all_aeromma_flights(mrg_dir_path, index_file_path, sub_directory = True):\n",
    "    for flight_dir in sorted(os.listdir(mrg_dir_path)):\n",
    "        if 'AEROMMA' in flight_dir:\n",
    "            if sub_directory == True:\n",
    "                mrg_file_path = mrg_dir_path + '/' + flight_dir + '/' + flight_dir + '.csv'\n",
    "            elif sub_directory == False:\n",
    "                mrg_file_path = mrg_dir_path + '/' + flight_dir + '.csv'\n",
    "            if os.path.exists(index_file_path) == True:\n",
    "                pair_aeromma_flight(mrg_file_path, index_file_path)\n",
    "            elif os.path.exists(index_file_path) == False:\n",
    "                pair_aeromma_flight(mrg_file_path, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e18af2-f1ef-42f2-890f-045b62c0b677",
   "metadata": {},
   "source": [
    "# Extract AEROMMA Data\n",
    "\n",
    "### List AEROMMA merge file variable names\n",
    "Shows the user what variables are available in an AEROMMA merge file.  \n",
    "  \n",
    "Parameters:  \n",
    "* `file_path` (str) - path of the AEROMMA merge file which the variable names should be read from\n",
    "* `rows` (bool) - tells the function whether to print each variable name on a new row (enter `True` for this option) or to just print out the whole list of variable names in one go (enter `False` for this option). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b515a-d588-481d-b934-cb12abaa1fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_vars(file_path, rows = False):\n",
    "    flight_data = pd.read_csv(file_path)\n",
    "    var_list = list(flight_data.keys())\n",
    "    \n",
    "    if rows == True:\n",
    "        for var_name in var_list:\n",
    "            print(var_name)\n",
    "    elif rows == False:\n",
    "        print(var_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71137277-4052-49ac-9120-30d024548513",
   "metadata": {},
   "source": [
    "### Extract desired AEROMMA variables\n",
    "The purpose of the `extract_flight_data()` function is to pull out all wanted variables from an AEROMMA merge file and put them into a pandas DataFrame indexed by time.  \n",
    "  \n",
    "Parameters:\n",
    "* `mrg_file_path` (str) - The path of the AEROMMA merge file for the desired flight. Can be a relative or absolute path, but absolute is recommended.\n",
    "* `output_vars` (list or NoneType) [Default: `None`] - list of AEROMMA variables to be extracted. If left as None, all AEROMMA variables will be extracted.  \n",
    "\n",
    "Returns:  \n",
    "* `sec_data` (pandas.DataFrame) - Contains flight coordinate data in addition to all desired AEROMMA variables indexed by observation timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c7cc6-bf7b-4ff7-b0ac-69ac317ae746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_flight_data(mrg_file_path, output_vars = None):\n",
    "    if output_vars == None:    #If no variables are listed for specific extraction, all variables are extracted here\n",
    "        sec_data = pd.read_csv(mrg_file_path).set_index('Time')\n",
    "    elif output_vars != None:    #If extraction variables are listed, this section extracts these specific variables in addition to coordinate variables\n",
    "        sec_data = find_coords(mrg_file_path)\n",
    "        extra = pd.read_csv(mrg_file_path).set_index('Time')\n",
    "        for var_name in output_vars:\n",
    "            try:\n",
    "                sec_data[var_name] = extra[var_name][:]\n",
    "            except KeyError:\n",
    "                sec_data[var_name] = np.nan\n",
    "                warn(var_name + ' not found in \"' + mrg_file_path + '\". Setting all values in column to np.nan.')\n",
    "    return sec_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a811742-c84f-4bb6-986b-a57d53735359",
   "metadata": {},
   "source": [
    "# QC AEROMMA Data\n",
    "\n",
    "### Remove negative values that do not belong in the 1 Hz data\n",
    "The purpose of the `rm_1hz_negatives()` function is to remove negative values from data columns that should not have negative values. For the columns that should not have negative values, this function replaces all negative values with `numpy.nan`. There are some variables in AEROMMA Merge files that should have negative values included. These values are included in the `ignore_cols` list. However, this is not an exhaustive list of all variables that can have negatives. Additional variables can be ignored by the negative removal process by adding the variable names to the `extra_ignore` list.  \n",
    "\n",
    "Parameters:  \n",
    "* `sec_data` (pandas.DataFrame) - Contains flight coordinate data in addition to all desired AEROMMA variables indexed by observation timestamp.\n",
    "* `extra_ignore` (list) [Default: `[]`] - List of AEROMMA variables that should not under go the process removing negative values in addition to the standard list of variables: `['G_LAT', 'G_LONG', 'ROLL', 'PITCH', 'YAW', 'AOA', 'U', 'V', 'W']`.  \n",
    "\n",
    "Returns:\n",
    "* `sec_data` (pandas.DataFrame) - Contains flight coordinate data in addition to all desired AEROMMA variables indexed by observation timestamp and has negative values removed from columns that should not have them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f2a309-e198-468f-87d9-02c4e7d0dec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_1hz_negatives(sec_data, extra_ignore = []):\n",
    "    #create a list of variables that normally have negative values. Allow the user to add extra variables \n",
    "    #that are not included in the basic \"ignore_cols\" list. \n",
    "    ignore_cols = ['G_LAT', 'G_LONG', 'ROLL', 'PITCH', 'YAW', 'AOA', 'U', 'V', 'W']\n",
    "    for var_name in extra_ignore:\n",
    "        ignore_cols.append(var_name)\n",
    "    \n",
    "    #replace negative values with np.nan in columns that do not normally have negatives\n",
    "    for key in sec_data.keys():\n",
    "        if key not in ignore_cols:\n",
    "            sec_data[key] = sec_data[key].apply(lambda x: np.nan if x < 0 else x)\n",
    "    \n",
    "    return sec_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11069004-ea1c-4e58-8dff-07ff28bc6f36",
   "metadata": {},
   "source": [
    "### Remove times where aircraft is outside model domain\n",
    "the purpose of the `rm_outside_model_times()` function is to create a list of times where the CMAQ extraction output has marked an AEROMMA observtion as taking place outside the model domain. Using that list of times, it removes the associated values from all variables in both the CMAQ and AEROMMA DataFrames.  \n",
    "\n",
    "Parameters:  \n",
    "* `cmaq_df` (pandas.DataFrame) - DataFrame containing CMAQ data paired to an AEROMMA flight\n",
    "* `agg_df` (pandas.DataFrame) - DataFrame of AEROMMA flight data aggregated to a regular timestep  \n",
    "\n",
    "Returns:\n",
    "* `cmaq_df` (pandas.DataFrame) - DataFrame containing CMAQ data paired to an AEROMMA flight. Data from times where the aircraft was outside the model domain has been removed.\n",
    "* `agg_df` (pandas.DataFrame) - DataFrame of AEROMMA flight data aggregated to a regular timestep. Data from times where the aircraft was outside the model domain has been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2785706f-1a29-4ea0-be11-3f5c0952e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_outside_model_times(cmaq_df, agg_df):\n",
    "    #If the aircraft is outside the CMAQ domain, all values in the row are marked with -9999.9999\n",
    "    #bad_times is essentially a list of times when all data frame row values are -9999.9999\n",
    "    bad_times = list(cmaq_df.loc[cmaq_df.nunique(axis = 1) == 1].index)\n",
    "    cmaq_df = cmaq_df.drop(bad_times)\n",
    "    agg_df = agg_df.drop(bad_times)\n",
    "    return cmaq_df, agg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b1eb7e-2c01-4d5b-ac6f-8e7155462357",
   "metadata": {},
   "source": [
    "### Remove CMAQ data where AEROMMA data is missing\n",
    "The purpose of the `mk_cmaq_missing()` function is to replace valid CMAQ data with `np.nan` for times when the corresponding AEROMMA data also missing. This makes sure that all CMAQ data that gets used has a 1-to-1 correspondence with AEROMMA observations.\n",
    "\n",
    "Parameters:  \n",
    "* `cmaq_array` (vector) - any 1d array-like object containing CMAQ data\n",
    "* `aeromma_array` (vector) - any 1d array-like object containing AEROMMA data\n",
    "\n",
    "Returns:\n",
    "* `cmaq_array` (np.ndarray) - a 1d numpy array with the same data as the original `cmaq_array` but with some data replaced with `np.nan` at indices where `aeromma_array` has the value of `np.nan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c7acb9-36ef-485e-901a-6501f0b0fb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_cmaq_missing(cmaq_array, aeromma_array):\n",
    "    #force both arrays to be in np.ndarray format\n",
    "    cmaq_array = np.array(cmaq_array)\n",
    "    aeromma_array = np.array(aeromma_array)\n",
    "    \n",
    "    #reset values of the CMAQ array to NaN when the AEROMMA data is missing\n",
    "    for i, aeromma in enumerate(aeromma_array):\n",
    "        if np.isnan(aeromma) == True:\n",
    "            cmaq_array[i] = np.nan\n",
    "    \n",
    "    return cmaq_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d23d69-c427-4e15-976e-1c4600cdcaab",
   "metadata": {},
   "source": [
    "### Calculate percentage of data that is missing\n",
    "The purpose of `pct_missing()` is to calculate the percent of data in a DataFrame column that is missing.\n",
    "\n",
    "Parameters:  \n",
    "* `var_name` (str) - The name of the data column you would like to analyze\n",
    "* `df` (pandas.DataFrame) - The DataFrame contining the data column you would like to analyze\n",
    "\n",
    "returns:  \n",
    "The percent of data in the selected data column (`df[var_name]`) that has a value of `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f17e9-b597-4c67-8dbc-6cdb249a19a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_missing(var_name, df):\n",
    "    all_data = len(df[var_name])\n",
    "    missing_data = len(df[var_name].loc[np.isnan(df[var_name])])\n",
    "    return 100 * (missing_data / all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193f779b",
   "metadata": {},
   "source": [
    "### Stats Table\n",
    "The purpose of `stats_table()` is to produce a table of statistics comparing a variable from CMAQ and an equivalent variable from AEROMMA. It also calculates the bias (CMAQ - AEROMMA) and the absolute error (|bias|) of all CMAQ values paired to AEROMMA observations and calculates the same statistics on the new bias and absolute error arrays. The statistics computed for each array are:  \n",
    "* mean\n",
    "* median\n",
    "* standard deviation\n",
    "* minimum\n",
    "* maximum\n",
    "* percent missing  \n",
    "\n",
    "Parameters:  \n",
    "* `cmaq_data` (vector like) - A vector of values representing data from CMAQ output\n",
    "* `aeromma_data` (vector like) - A vector of values representing AEROMMA observations\n",
    "* `var_name` (str) - Name of the variable being analyzed with the statistics\n",
    "* `var_units` (str) - Units of the variable being analyzed with the statistics\n",
    "* `save_txt` (str or bool) [Default: `False`] - If not `False`, the path of a new text file to save the resulting stats table to. No table will be printed if the value is changed from `False`.\n",
    "\n",
    "Returns:\n",
    "* stats_dict (dict) - a dictionary storing all the statistics shown in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdedcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_stats is a function used for stats_table. Scroll down to view stats_table\n",
    "def calc_stats(data, missing_data, stats_dict, key):\n",
    "    if missing_data < 100:\n",
    "        stats_dict[key] = {'mean': np.nanmean(data), \n",
    "                           'median': np.nanmedian(data), \n",
    "                           'std': np.nanstd(data), \n",
    "                           'q1': np.nanquantile(data, 0.25), \n",
    "                           'q3': np.nanquantile(data, 0.75), \n",
    "                           'min': np.nanmin(data), \n",
    "                           'max': np.nanmax(data)}\n",
    "    else:\n",
    "        stats_dict[key] = {'mean': np.nan, \n",
    "                           'median': np.nan, \n",
    "                           'std': np.nan, \n",
    "                           'q1': np.nan, \n",
    "                           'q3': np.nan, \n",
    "                           'min': np.nan, \n",
    "                           'max': np.nan}\n",
    "    return stats_dict\n",
    "        \n",
    "\n",
    "def stats_table(cmaq_data, aeromma_data, var_name, var_units, save_txt = False):\n",
    "    #create an empty dictionary to store the statistics\n",
    "    stats_dict = {}\n",
    "\n",
    "    #caclulate the percentage of missing data\n",
    "    missing_data = pct_missing('var', pd.DataFrame({'var': cmaq_data}))\n",
    "    \n",
    "    #calculate CMAQ and AEROMMA statistics\n",
    "    stats_dict = calc_stats(cmaq_data, missing_data, stats_dict, 'CMAQ')\n",
    "    stats_dict = calc_stats(aeromma_data, missing_data, stats_dict, 'AEROMMA')\n",
    "\n",
    "    #find the difference and absolute error between CMAQ and AEROMMA data\n",
    "    bias_values = cmaq_data - aeromma_data\n",
    "    abs_error = np.abs(bias_values)\n",
    "    \n",
    "    #calculate bias statistics\n",
    "    stats_dict = calc_stats(bias_values, missing_data, stats_dict, 'bias')\n",
    "    stats_dict = calc_stats(abs_error, missing_data, stats_dict, 'abs_error')\n",
    "\n",
    "    #create statistics table\n",
    "    table_title = 'Statistics for ' + var_name + ' [' + var_units + ']'\n",
    "    if save_txt == False:\n",
    "        print()\n",
    "        print(table_title)\n",
    "        print('-' * len(table_title))\n",
    "        print('+----------------+-----------------+-----------------+-----------------+-----------------+')\n",
    "        print('|  Statistic     |      CMAQ       |     AEROMMA     |      Bias       | Absolute Error  |')\n",
    "        print('+----------------+-----------------+-----------------+-----------------+-----------------+')\n",
    "        print('|  Mean          |  %13.5f  |  %13.5f  |  %13.5f  |  %13.5f  |' % (stats_dict['CMAQ']['mean'], stats_dict['AEROMMA']['mean'], stats_dict['bias']['mean'], stats_dict['abs_error']['mean']))\n",
    "        print('+----------------+-----------------+-----------------+-----------------+-----------------+')\n",
    "        print('|  Median        |  %13.5f  |  %13.5f  |  %13.5f  |  %13.5f  |' % (stats_dict['CMAQ']['median'], stats_dict['AEROMMA']['median'], stats_dict['bias']['median'], stats_dict['abs_error']['median']))\n",
    "        print('+----------------+-----------------+-----------------+-----------------+-----------------+')\n",
    "        print('|  Std Dev       |  %13.5f  |  %13.5f  |  %13.5f  |  %13.5f  |' % (stats_dict['CMAQ']['std'], stats_dict['AEROMMA']['std'], stats_dict['bias']['std'], stats_dict['abs_error']['std']))\n",
    "        print('+----------------+-----------------+-----------------+-----------------+-----------------+')\n",
    "        print('|  Quartile 1    |  %13.5f  |  %13.5f  |  %13.5f  |  %13.5f  |' % (stats_dict['CMAQ']['q1'], stats_dict['AEROMMA']['q1'], stats_dict['bias']['q1'], stats_dict['abs_error']['q1']))\n",
    "        print('+----------------+-----------------+-----------------+-----------------+-----------------+')\n",
    "        print('|  Quartile 3    |  %13.5f  |  %13.5f  |  %13.5f  |  %13.5f  |' % (stats_dict['CMAQ']['q3'], stats_dict['AEROMMA']['q3'], stats_dict['bias']['q3'], stats_dict['abs_error']['q3']))\n",
    "        print('+----------------+-----------------+-----------------+-----------------+-----------------+')\n",
    "        print('|  Minimum       |  %13.5f  |  %13.5f  |  %13.5f  |  %13.5f  |' % (stats_dict['CMAQ']['min'], stats_dict['AEROMMA']['min'], stats_dict['bias']['min'], stats_dict['abs_error']['min']))\n",
    "        print('+----------------+-----------------+-----------------+-----------------+-----------------+')\n",
    "        print('|  Maximum       |  %13.5f  |  %13.5f  |  %13.5f  |  %13.5f  |' % (stats_dict['CMAQ']['max'], stats_dict['AEROMMA']['max'], stats_dict['bias']['max'], stats_dict['abs_error']['max']))\n",
    "        print('+----------------+-----------------+-----------------+-----------------+-----------------+')\n",
    "        print('|  Missing Data  |  %12.4f%%  |  %12.4f%%  |  %12.4f%%  |  %12.4f%%  |' % (missing_data, missing_data, missing_data, missing_data))\n",
    "        print('+----------------+-----------------+-----------------+-----------------+-----------------+')\n",
    "        print()\n",
    "\n",
    "    #save the table to a text file if the user requests it\n",
    "    if save_txt != False:\n",
    "        file = open(save_txt, 'w')\n",
    "        file.write(table_title + '\\n')\n",
    "        file.write('-' * len(table_title) + '\\n')\n",
    "        file.write('+----------------+-----------------+-----------------+-----------------+-----------------+\\n')\n",
    "        file.write('|  Statistic     |      CMAQ       |     AEROMMA     |      Bias       | Absolute Error  |\\n')\n",
    "        file.write('+----------------+-----------------+-----------------+-----------------+-----------------+\\n')\n",
    "        file.write('|  Mean          |  %13.5f  |  %13.5f  |  %13.5f  |  %13.5f  |\\n' % (stats_dict['CMAQ']['mean'], stats_dict['AEROMMA']['mean'], stats_dict['bias']['mean'], stats_dict['abs_error']['mean']))\n",
    "        file.write('+----------------+-----------------+-----------------+-----------------+-----------------+\\n')\n",
    "        file.write('|  Median        |  %13.5f  |  %13.5f  |  %13.5f  |  %13.5f  |\\n' % (stats_dict['CMAQ']['median'], stats_dict['AEROMMA']['median'], stats_dict['bias']['median'], stats_dict['abs_error']['median']))\n",
    "        file.write('+----------------+-----------------+-----------------+-----------------+-----------------+\\n')\n",
    "        file.write('|  Std Dev       |  %13.5f  |  %13.5f  |  %13.5f  |  %13.5f  |\\n' % (stats_dict['CMAQ']['std'], stats_dict['AEROMMA']['std'], stats_dict['bias']['std'], stats_dict['abs_error']['std']))\n",
    "        file.write('+----------------+-----------------+-----------------+-----------------+-----------------+\\n')\n",
    "        file.write('|  Quartile 1    |  %13.5f  |  %13.5f  |  %13.5f  |  %13.5f  |\\n' % (stats_dict['CMAQ']['q1'], stats_dict['AEROMMA']['q1'], stats_dict['bias']['q1'], stats_dict['abs_error']['q1']))\n",
    "        file.write('+----------------+-----------------+-----------------+-----------------+-----------------+\\n')\n",
    "        file.write('|  Quartile 3    |  %13.5f  |  %13.5f  |  %13.5f  |  %13.5f  |\\n' % (stats_dict['CMAQ']['q3'], stats_dict['AEROMMA']['q3'], stats_dict['bias']['q3'], stats_dict['abs_error']['q3']))\n",
    "        file.write('+----------------+-----------------+-----------------+-----------------+-----------------+\\n')\n",
    "        file.write('|  Minimum       |  %13.5f  |  %13.5f  |  %13.5f  |  %13.5f  |\\n' % (stats_dict['CMAQ']['min'], stats_dict['AEROMMA']['min'], stats_dict['bias']['min'], stats_dict['abs_error']['min']))\n",
    "        file.write('+----------------+-----------------+-----------------+-----------------+-----------------+\\n')\n",
    "        file.write('|  Maximum       |  %13.5f  |  %13.5f  |  %13.5f  |  %13.5f  |\\n' % (stats_dict['CMAQ']['max'], stats_dict['AEROMMA']['max'], stats_dict['bias']['max'], stats_dict['abs_error']['max']))\n",
    "        file.write('+----------------+-----------------+-----------------+-----------------+-----------------+\\n')\n",
    "        file.write('|  Missing Data  |  %12.4f%%  |  %12.4f%%  |  %12.4f%%  |  %12.4f%%  |\\n' % (missing_data, missing_data, missing_data, missing_data))\n",
    "        file.write('+----------------+-----------------+-----------------+-----------------+-----------------+\\n')\n",
    "        file.close()\n",
    "        print('Statistics table saved to: ' + save_txt)\n",
    "\n",
    "    return stats_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42340eb7-dac9-49cc-b62e-14e3024b56d1",
   "metadata": {},
   "source": [
    "# Plotting Functions\n",
    "\n",
    "### Compare AEROMMA data and paired CMAQ output\n",
    "The purpose of the `compare_plot()` function is to create a plot based on values from an AEROMMA flight and CMAQ values paired to the flight location in addition to the flight ID and the name of the variable the AEROMMA and CMAQ values represent. If the CMAQ data is accurately reproducing what AEROMMA observed, the plotted points should fall along the line y = x, which plots in black. Any point that does not fall along the line represents a disagreement between AEROMMA observations and CMAQ output.  \n",
    "  \n",
    "Parameters:  \n",
    "* `var_name` (str) - the name of the variable being plotted from AEROMMA and CMAQ data\n",
    "* `flight_values` (vector like) - a vector containing the values from an AEROMMA variable\n",
    "* `cmaq_values` (vector like) - a vector of CMAQ values that are paired to an equivalent data AEROMMA vector\n",
    "* `var_units` (str) - the units of the variable\n",
    "* `title_start` (str) [Default: `''`] - Text included at the begining of the figure title. Title string is `title_start + 'CMAQ vs AEROMMA\\n' + var_name + ' [' + var_units + ']'`\n",
    "* `fig_side_length` (float) [Default: `3.5`] - Changes the size of the figure. The figure shape is set to always be a square, so this parameter changes the length of a side of the square.\n",
    "* `save_fig` (str or bool) [Default: `False`] - The full path and filename to save the figure to. If no string is provided, the resulting figure will not be saved as a file.\n",
    "\n",
    "Returns:\n",
    "* `None`. Instead, a plot is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7655e12c-f03e-4861-ba55-3515b066df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_plot(var_name, flight_values, cmaq_values, var_units, title_start = '', fig_side_length = 5, save_fig = False):  \n",
    "    #remove missing values and force the CMAQ and AEROMMA data to be in np.ndarray format\n",
    "    cmaq_values = mk_cmaq_missing(cmaq_values, flight_values)\n",
    "    cmaq_values = [value for value in cmaq_values if np.isnan(value) == False]\n",
    "    flight_values = [value for value in flight_values if np.isnan(value) == False]\n",
    "\n",
    "    #if data exists...\n",
    "    if len(cmaq_values) > 0 and len(flight_values) > 0:\n",
    "        #find the maximum and minimum value of combined flight and CMAQ data\n",
    "        combined_array = []\n",
    "        for i in range(len(flight_values)):\n",
    "            combined_array.append(flight_values[i])\n",
    "            combined_array.append(cmaq_values[i])\n",
    "        max_value = np.nanmax(combined_array)\n",
    "        min_value = np.nanmin(combined_array)\n",
    "        max_min_diff = max_value - min_value\n",
    "        max_value_plus = np.int32(np.ceil(max_value + max_min_diff * 0.05))\n",
    "        min_value_plus = np.int32(np.floor(min_value - max_min_diff * 0.05))\n",
    "        max_to_min_array = [min_value_plus - 1 + n for n in range(max_value_plus - min_value_plus + 2)]\n",
    "\n",
    "        #remove times with missing data\n",
    "        points_df = pd.DataFrame({'x':flight_values, 'y':cmaq_values})\n",
    "        points_df = points_df.loc[points_df.notna().all(axis = 1)]\n",
    "        \n",
    "        #calculate point density\n",
    "        points_array = np.vstack([np.array(points_df['x']), np.array(points_df['y'])])\n",
    "        try:\n",
    "            density = sp_stat.gaussian_kde(points_array)(points_array)\n",
    "            calc_density = True\n",
    "        except:\n",
    "            calc_density = False\n",
    "\n",
    "    else:\n",
    "        warn('Data provided does not contain any values to plot. Resulting plot will be empty.')\n",
    "        min_value_plus = -1\n",
    "        max_value_plus = 1\n",
    "        max_to_min_array = [min_value_plus - 1 + n for n in range(max_value_plus - min_value_plus + 2)]\n",
    "\n",
    "\n",
    "    #plot the flight and CMAQ values against each other\n",
    "    fig = plot.Figure()\n",
    "    plot.rcParams['figure.figsize'] = (fig_side_length + 1, fig_side_length)\n",
    "    plot.title(title_start + 'CMAQ vs AEROMMA\\n' + var_name + ' [' + var_units + ']')\n",
    "    plot.xlabel('AEROMMA ' + var_name)\n",
    "    plot.ylabel('CMAQ ' + var_name)\n",
    "    if len(cmaq_values) > 0 and len(flight_values) > 0:\n",
    "        if calc_density == True:\n",
    "            points = plot.scatter(np.array(points_df['x']), np.array(points_df['y']), c = density, cmap = 'plasma', s = 10, zorder = 1)\n",
    "            cbar = plot.colorbar(points, label = 'Point Density', ticks = [np.min(density), np.max(density)])\n",
    "            cbar.ax.set_yticklabels(['Low', 'High'])\n",
    "        elif calc_density == False:\n",
    "            plot.scatter(np.array(points_df['x']), np.array(points_df['y']), color = 'g', s = 10, zorder = 1)\n",
    "    plot.plot(max_to_min_array, max_to_min_array, color = 'k', zorder = 5)    \n",
    "    plot.xlim((min_value_plus, max_value_plus))\n",
    "    plot.ylim((min_value_plus, max_value_plus))\n",
    "    for value in plot.gca().get_yticks():\n",
    "        value = float(value)\n",
    "        plot.plot([min_value_plus, max_value_plus], [value, value], color = 'k', linestyle = '--', linewidth = 0.5, zorder = 3)\n",
    "        plot.plot([value, value], [min_value_plus, max_value_plus], color = 'k', linestyle = '--', linewidth = 0.5, zorder = 3)\n",
    "    if save_fig != False:\n",
    "        plot.savefig(save_fig)\n",
    "    elif save_fig == False:\n",
    "        plot.show()\n",
    "    plot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692d59de-4b2d-43ba-a16f-ea3a46e697c3",
   "metadata": {},
   "source": [
    "### Compare AEROMMA and CMAQ coordinate data\n",
    "The purpose of the `coord_checks()` function is to produce a series of comparison plots (generated by `compare_plot()`) based on the coordinate variables within AEROMMA and CMAQ data. These data are automatically extracted when pulling out any paired CMAQ data and, therefore, will always be availabe when CMAQ data is extracted.  \n",
    "\n",
    "Parameters:  \n",
    "* `flight_id` (str) - the string identifying the AEROMMA flight currently being used.\n",
    "* `cmaq_df` (pandas.DataFrame) - DataFrame containing exracted CMAQ data that has been paired to the AEROMMA flight with the listed flight ID\n",
    "* `agg_df` (pandas.DataFrame) - DataFrame containing AEROMMA flight data with the listed flight ID aggregated to a one minute time step.\n",
    "* `descriptions` (bool) [Default: `True`] - If set to `True`, the function will add additional information describing what the plot should look like if everything has paired correctly. If set to `False`, the function will not produce this additional information.\n",
    "* `save_figs` (str or bool) [Default: `False`] - The absolute path of the directory to save the figure to. The file name is provided by the function. If no string is provided, the resulting figure will not be saved as a file.\n",
    "\n",
    "Returns:\n",
    "* `None`. Instead, a plot is created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc64426-7005-46a6-a495-2c5f1b1019b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_checks(flight_id, cmaq_df, agg_df, descriptions = True, save_figs = False):\n",
    "    #CMAQ coordinate extraction\n",
    "    cmaq_times = cmaq_df.index\n",
    "    cmaq_lons = cmaq_df['LON']\n",
    "    cmaq_lats = cmaq_df['LAT']\n",
    "    cmaq_alts = cmaq_df['ALT']\n",
    "    \n",
    "    #AEROMMA coordinate extraction\n",
    "    flight_times = agg_df.index\n",
    "    flight_lons = agg_df['G_LONG']\n",
    "    flight_lats = agg_df['G_LAT']\n",
    "    flight_alts = agg_df['G_ALT']\n",
    "    \n",
    "    #converts date format to an integer\n",
    "    cmaq_times = [int(datetime.datetime.strptime(time, '%Y-%m-%d %H:%M:%S').strftime('%m%d%H%M%S')) for time in cmaq_times]\n",
    "    flight_times = [int(datetime.datetime.strptime(time, '%Y-%m-%d %H:%M:%S').strftime('%m%d%H%M%S')) for time in flight_times]\n",
    "    \n",
    "    #plot data\n",
    "    print('-------------------------------------------------------------------------------------------------------------')\n",
    "    print('Comparison of coordinate data in AEROMMA and CMAQ for ' + flight_id)\n",
    "    if save_figs == False:\n",
    "        compare_plot('Time', flight_times, cmaq_times, 'YYYYMMDDHHmmSS', title_start = flight_id + ' ')\n",
    "    elif save_figs != False:\n",
    "        compare_plot('Time', flight_times, cmaq_times, 'YYYYMMDDHHmmSS', title_start = flight_id + ' ', save_fig = os.path.join(save_figs, 'time_comparison.png'))\n",
    "    if descriptions == True:\n",
    "        print('In the case of the time plot, all plots should be exactly on the line y = x. The index of every row in') \n",
    "        print('the DataFrame is based on the time stamp of the AEROMMA observation so all values should match extactly')\n",
    "        print('in each data set. Any variation from y = x represents a mismatch in the data and needs to be addressed.')\n",
    "        print('To clarify, the label on the y-axis, \"CMAQ Time\", is misleading in this case because the time does not')\n",
    "        print('come from CMAQ, it comes from AEROMMA.')\n",
    "    # print()\n",
    "    if save_figs == False:\n",
    "        compare_plot('LON', flight_lons, cmaq_lons, '°', title_start = flight_id + ' ')\n",
    "        compare_plot('LAT', flight_lats, cmaq_lats, '°', title_start = flight_id + ' ')\n",
    "    elif save_figs != False:\n",
    "        compare_plot('LON', flight_lons, cmaq_lons, '°', title_start = flight_id + ' ', save_fig = os.path.join(save_figs, 'latitude_comparison.png'))\n",
    "        compare_plot('LAT', flight_lats, cmaq_lats, '°', title_start = flight_id + ' ', save_fig = os.path.join(save_figs, 'longitude_comparison.png'))\n",
    "    if descriptions == True:\n",
    "        print('For latitude and longitude, there should be some variation aroundthe line y = x, but only slight. Any')\n",
    "        print('clear deviation from the line represents a mismatch in the data.')\n",
    "    print()\n",
    "    if save_figs == False:\n",
    "        compare_plot('ALT', flight_alts, cmaq_alts, 'm', title_start = flight_id + ' ')\n",
    "    elif save_figs != False:\n",
    "        compare_plot('ALT', flight_alts, cmaq_alts, 'm', title_start = flight_id + ' ', save_fig = os.path.join(save_figs,  'altitude_comparison.png'))\n",
    "    if descriptions == True:\n",
    "        print('For altitude, expect some minor scatter around the line y = x, especially at higher altitudes. After a')\n",
    "        print('certain altitude, the points should become spread out along lines of equal CMAQ height, representing')\n",
    "        print('the grid point altitudes in the model. The values should all be in terms of height above sea level. If')\n",
    "        print('a majority of values are clearly below the line y = x, there is a good chance the CMAQ extraction was')\n",
    "        print('set to height above ground level. Otherwise, any other significant scatter is a sign of mismatched data.')\n",
    "    print('-------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d1379-5bb1-4bb4-a0a4-d0fc65a8cfdd",
   "metadata": {},
   "source": [
    "### Compare AEROMMA and CMAQ meteorological data\n",
    "The purpose of the met_compare() function is to produce a series of comparison plots (generated by compare_plot()) based on the meteorological variables within AEROMMA and CMAQ data. These variables are:  \n",
    "* Temperature (AEROMMA: `'T'`, CMAQ: `'TA'`)\n",
    "* Pressure (AEROMMA: `'P'`, CMAQ: `'PRES'`)\n",
    "\n",
    "If an output_vars list is passed to the CMAQ or AEROMMA extraction functions, these variables are not automatically extracted and will need to be added to the output_vars list for this function to run sucessfully.\n",
    "\n",
    "Parameters:  \n",
    "* `flight_id` (str) - the string identifying the AEROMMA flight currently being used.\n",
    "* `cmaq_df` (pandas.DataFrame) - DataFrame containing exracted CMAQ data that has been paired to the AEROMMA flight with the listed flight ID\n",
    "* `agg_df` (pandas.DataFrame) - DataFrame containing AEROMMA flight data with the listed flight ID aggregated to a one minute time step.\n",
    "* `save_figs` (str or bool) [Default: `False`] - The absolute path of the directory to save the figure to. The file name is provided by the function. If no string is provided, the resulting figure will not be saved as a file.\n",
    "\n",
    "Returns:\n",
    "* `None`. Instead, a plot is created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27297c03-d0d0-4c17-bf1c-331b5cb2b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def met_compare(flight_id, cmaq_df, agg_df, save_figs = False):\n",
    "    #CMAQ coordinate extraction\n",
    "    cmaq_t = cmaq_df['TA']\n",
    "    cmaq_p = cmaq_df['PRES'] / 100\n",
    "    \n",
    "    #AEROMMA coordinate extraction\n",
    "    flight_t = agg_df['T'] / 100\n",
    "    flight_p = agg_df['P'] / 100\n",
    "    \n",
    "    #plot data\n",
    "    print('-------------------------------------------------------------------------------------------------------------')\n",
    "    print('Comparison of coordinate data in AEROMMA and CMAQ for ' + flight_id)\n",
    "    if save_figs == False:\n",
    "        compare_plot('Temperature', flight_t, cmaq_t, 'K', title_start = flight_id + ' ')\n",
    "        compare_plot('Pressure', flight_p, cmaq_p, 'Pa', title_start = flight_id + ' ')\n",
    "\n",
    "    elif save_figs != False:\n",
    "        compare_plot('Temperature', flight_t, cmaq_t, 'K', title_start = flight_id + ' ', save_fig = os.path.join(save_figs,'temperature_comparison.png'))\n",
    "        compare_plot('Pressure', flight_p, cmaq_p, 'mb', title_start = flight_id + ' ', save_fig = os.path.join(save_figs, 'pressure_comparison.png'))\n",
    "    print('-------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2000d7",
   "metadata": {},
   "source": [
    "### Time Series\n",
    "The purpose of the `time_series()` function is to create a plot of one or more variables with the same units over a period of time.\n",
    "\n",
    "Parameters:\n",
    "* `times` (vector like) - Provides a list of times all in the string format `'YYYY-MM-DD HH:mm:SS'`. This vector will provide the x-values for the plot.\n",
    "* `values_lists` (list) - Provides a series of vector like objects, each vector within `values lists` representing a new time series. The values in these vectors should represent y-values for the plot. The number of time series plotted depends on the number of vectors added to `values_list`.\n",
    "* `var_name_list` (list) - Each list item should be a string that represents the name of the variable in the corresponding values list in `values_lists`. These will be used at plot labels.\n",
    "* `colors` (list or NoneType) [Default: `None`] - Each list item should be a matplotlib color name corresponding to the variable in `var_name_list`.\n",
    "* `plot_title` (str or NoneType) [Default: `None`] - The title of the plot.\n",
    "* `y_label` (str or NoneType) [Default: `None`] - The label on the y-axis.\n",
    "* `time_range` (list or NoneType) [Default: `None`] - A list of two date strings that set the x-limits of the plot with the format `[start_date, end_date]`. The date strings should have the same date format as the date strings in the `times` vector.\n",
    "* `save_fig` (str or bool) [Default: `False`] - The full path and filename to save the figure to. If no string is provided, the resulting figure will not be saved as a file.\n",
    "\n",
    "Returns:\n",
    "* `None`. Instead, a figure is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1acbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series(times, values_lists, var_name_list, colors = None, plot_title = None, y_label = None, time_range = None, save_fig = False):\n",
    "    #convert times to a datetime format\n",
    "    times = [datetime.datetime.strptime(time, '%Y-%m-%d %H:%M:%S') for time in times]\n",
    "\n",
    "    #convert_times to a datetime format if time_range is provided\n",
    "    if time_range != None:\n",
    "        time_range = [datetime.datetime.strptime(time, '%Y-%m-%d %H:%M:%S') for time in time_range]\n",
    "        \n",
    "    #force values_lists vectors to be in list format\n",
    "    for i, values_list in enumerate(values_lists):\n",
    "        values_lists[i] = list(values_list)\n",
    "\n",
    "    #find times between flights\n",
    "    for i in range(len(times) - 1):\n",
    "        if times[i + 1] - times[i] > datetime.timedelta(minutes = 5):\n",
    "            times.insert(i + 1, times[i] + datetime.timedelta(minutes = 5))    #adds an extra time point to the list\n",
    "            for j in range(len(values_lists)):\n",
    "                values_lists[j].insert(i + 1, np.nan)    #adds a NaN value to the extra time point for each variable\n",
    "    \n",
    "    #Create the figure\n",
    "    fig = plot.figure()\n",
    "\n",
    "    if plot_title != None:\n",
    "        plot.title(plot_title)\n",
    "    if y_label != None:\n",
    "        plot.ylabel(y_label)\n",
    "    plot.xlabel('Time')\n",
    "    if time_range != None:\n",
    "        plot.xlim(time_range)\n",
    "    \n",
    "    #plot the data\n",
    "    for i, values_list in enumerate(values_lists):\n",
    "        if colors == None:\n",
    "            plot.plot(times, values_list, label = var_name_list[i])\n",
    "        else: \n",
    "            plot.plot(times, values_list, color = colors[i], label = var_name_list[i])\n",
    "    plot.legend(bbox_to_anchor=(1.05, 1))\n",
    "    plot.grid()\n",
    "    \n",
    "    #close the figure\n",
    "    if save_fig != False:\n",
    "        plot.savefig(save_fig)\n",
    "    if save_fig == False:\n",
    "        plot.show()\n",
    "    plot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4af8d57-a6ca-4326-8ac8-994bb60b962e",
   "metadata": {},
   "source": [
    "### Vertical Comparison\n",
    "The purpose of the `altitude_bins()` function is to add a column to a cleaned AEROMMA or CMAQ Pandas DataFrame that specifies what altitude bin a particular observation falls in. \n",
    "\n",
    "Parameters:  \n",
    "* `clean_df` (pandas.DataFrame) - a fully cleaned Pandas DataFrame that contains data from an AEROMMA flight either from CMAQ or AEROMMA itself. In other functions, these DataFrames are often refered to as `cmaq_df`, for cleaned CMAQ data, or `agg_df` for cleaned AEROMMA data.\n",
    "* `bin_width` (int) [Default: `500`] - The width of bins used to sort data based on altitude. \n",
    "* `first_bin_height` (int) [Default: `0`] - The height at which to start the bottom of the lowest level altitude bin.\n",
    "* `pre_def_bins` (list or NoneType) [Default: `None`] - User defined list of int and/or float values that define the edges of each altitude bin. The list should define both the top and bottom of each bin. Therefore, the number of bins will be equal to `len(list) - 1`. However, by default, the behavior set by `pre_def_bins` is ignored and the bins are created by the `bin_width` and `first_bin_height` parameters.\n",
    "* `add_to_df` (bool) [Default: `False`] - When set to `False`, the function will return a list of strings that represent the altitude bin of every observation in the dataset. When set to `True`, the function adds the list of strings to the DataFrame under the column name `'alt_bins'`.  \n",
    "\n",
    "Returns:\n",
    "* Depending on the value of `add_to_df`, `altitude_bins()` returns either a list of strings that indicate the altitude bin for every observation (when `add_to_df` is set to `False`) or, the same list is added to the `clean_df` DataFrame as a column named `'alt_bins'` and the whole DataFrame is returned.\n",
    "\n",
    "Notes:\n",
    "* It is imperative that for all DataFrames that will be compared against each other with the `plot_vert()` funtion, the settings for bin creation (the `bin_width`, `first_bin_height`, and `pre_def_bins`) be the same. Having differences will cause errors in the `plot_vert()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a630d00-da22-4d4f-9969-4f8b8a3f6701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def altitude_bins(clean_df, bin_width = 500, first_bin_height = 0, pre_def_bins = None, add_to_df = False):\n",
    "    #force all starting bin heights to be integers\n",
    "    first_bin_height = int(first_bin_height)\n",
    "    \n",
    "    #extract altitude data depending on if the data is from CMAQ or AEROMMA\n",
    "    if 'G_LONG' in clean_df.keys():    #AEROMMA data \n",
    "        alt_data = clean_df['G_ALT']\n",
    "    else:                        #CMAQ data\n",
    "        alt_data = clean_df['ALT']\n",
    "    \n",
    "    #create a list of bin values that represent the lowest value in the bin\n",
    "    if pre_def_bins == None:\n",
    "        max_height = alt_data.max()\n",
    "        current_bin_height = first_bin_height\n",
    "        bin_edge_values = []\n",
    "        bin_names = []\n",
    "        while current_bin_height - max_height < bin_width:\n",
    "            bin_edge_values.append(current_bin_height)\n",
    "            bin_names.append(str(current_bin_height) + ' < alt <= ' + str(current_bin_height + bin_width))\n",
    "            current_bin_height += bin_width\n",
    "        bin_edge_values.append(current_bin_height)\n",
    "    else:\n",
    "        bin_edge_values = pre_def_bins[:]\n",
    "        bin_names = []\n",
    "        for i in range(1, len(bin_edge_values)):\n",
    "            bin_names.append(str(bin_edge_values[i - 1]) + ' < alt <= ' + str(bin_edge_values[i]))\n",
    "    \n",
    "    #sort DataFrame rows into bins\n",
    "    bin_list = pd.cut(alt_data, bins = bin_edge_values, labels = bin_names)\n",
    "    if add_to_df == False:\n",
    "        return list(bin_list)\n",
    "    elif add_to_df == True:\n",
    "        clean_df['alt_bins'] = bin_list\n",
    "        return clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e3e8e2-77d7-4cd5-9ff0-6796d85a67cc",
   "metadata": {},
   "source": [
    "The purpose of the `plot_vert()` function is to produce a plot showing the variation of a given variable with altitude, potentially making comparisons between CMAQ and AEROMMA data or other kinds of comparison.\n",
    "\n",
    "Parameters:\n",
    "* `value_lists` (list) - A list of vector like objects where each vector in the list contains a series of values of the variable you would like to plot. Every vector within the `value_list` list repesents a new variable to be plotted.\n",
    "* `bin_lists` (list) - A list of vector like objects where each vector in the list contains a series of altitude bin names. The altitude bin names correspond to the values in `value_lists`. The number of vectors in `value_lists` and `bin_lists` should be the same.\n",
    "* `var_names` (list) - A list of strings that contain the variable name of each vector in `value_lists`. the length of `value_lists` and `var_names` should be the same.\n",
    "* `colors` (list) - A list of strings where each represents the color you would like to plot a specific variable. The color strings correspond to the variable names in `var_names` as well as the vectors in `value_lists` and `bin_lists`. The strings can either be [matplotlib colors](https://matplotlib.org/stable/gallery/color/named_colors.html) or color [hex codes](https://htmlcolorcodes.com/). \n",
    "* `x_label` (str or NoneType) [Default: `None`] - The label on the x-axis of the vertical plot. If no string is provided, there will be no x-axis label on the plot.\n",
    "* `title` (str or NoneType) [Default: `None`] - The title of the vertical plot. If no string is provided, there will be no plot title.\n",
    "* `save_fig` (str or bool) [Default: `False`] - The full path and filename to save the figure to. If no string is provided, the resulting figure will not be saved as a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d09b822-4380-4a4d-8e83-3c6135e571df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vert(bin_list, value_lists, var_names, colors, x_label = None, title = None, save_fig = False):\n",
    "    #force all lists of data and altitude vectors to be in list format\n",
    "    bin_list = list(bin_list)\n",
    "    for i in range(len(value_lists)):\n",
    "        value_lists[i] = list(value_lists[i])\n",
    "    \n",
    "    #construct a list of unique altitude bins ordered from lowest to hightest altitude\n",
    "    unique_bins = list(set(bin_list))    #creates a list of unique bin names\n",
    "    low_bin_edge = sorted([int(bin_name.split(' ')[0]) for bin_name in unique_bins])    #creates a sorted list of integers storing the lowest value of each bin\n",
    "    high_bin_edge = sorted([int(bin_name.split(' ')[-1]) for bin_name in unique_bins])    #creates a sorted list of integers storing the highest value of each bin\n",
    "    ordered_unique_bins = []\n",
    "    bin_centers = []\n",
    "    bin_widths = []\n",
    "    for low, high in zip(low_bin_edge, high_bin_edge):\n",
    "        ordered_unique_bins.append(str(low) + ' < alt <= ' + str(high))\n",
    "        bin_centers.append(np.mean([low, high]))\n",
    "        bin_widths.append(high - low)\n",
    "    bin_centers = np.array(bin_centers)\n",
    "    \n",
    "    #construct dictionaries to store data about each bin\n",
    "    bin_data = {}    #dictionary containing all the values for each bin   \n",
    "    bin_means = {}    #dictionary containing the mean value for each bin\n",
    "    bin_medians = {}    #dictionary containing the median value for each bin\n",
    "    for var_name in var_names:\n",
    "        bin_means[var_name] = []\n",
    "        bin_medians[var_name] = []\n",
    "        for bin_name in ordered_unique_bins:\n",
    "            bin_data[var_name + ', ' + bin_name] = []\n",
    "    \n",
    "    #sort data into bin_data and bin_means dictionaries\n",
    "    for value_list, var_name in zip(value_lists, var_names):\n",
    "        #sort each value into a list in bin_data so that all values for each bin for a variable\n",
    "        #are included \n",
    "        for value, bin_name in zip(value_list, bin_list):\n",
    "            bin_data[var_name + ', ' + bin_name].append(value)\n",
    "        \n",
    "        #Caluclate mean and median values within bin_data bins and assign the altitude bin the\n",
    "        #mean value in bin_means and median value in bin_medians\n",
    "        for bin_name in ordered_unique_bins:\n",
    "            bin_values = list(bin_data[var_name + ', ' + bin_name])\n",
    "            bin_values = [value for value in bin_values if np.isnan(value) == False]\n",
    "            if len(bin_values) > 0:\n",
    "                bin_means[var_name].append(np.mean(bin_values))\n",
    "                bin_medians[var_name].append(np.quantile(bin_values, 0.5))\n",
    "            else:\n",
    "                bin_means[var_name].append(np.nan) \n",
    "                bin_medians[var_name].append(np.nan)\n",
    "        \n",
    "    #find the total number of observations in each bin\n",
    "    bin_count = []\n",
    "    for bin_name in ordered_unique_bins:\n",
    "        non_nan_list = [value for value in bin_data[var_name + ', ' + bin_name] if np.isnan(value) == False]\n",
    "        bin_count.append(len(non_nan_list))\n",
    "                \n",
    "    #calculate and store the 1st and 3rd quartile values for each bin\n",
    "    bin_iqr = {}\n",
    "    for var_name in var_names:\n",
    "        for key in bin_data:\n",
    "            if var_name in key:\n",
    "                nan_check = [value for value in bin_data[key] if np.isnan(value) == False]\n",
    "                if len(nan_check) > 0:\n",
    "                    try:\n",
    "                        bin_iqr[var_name + 'q1'].append(np.nanquantile(bin_data[key], 0.25))\n",
    "                        bin_iqr[var_name + 'q3'].append(np.nanquantile(bin_data[key], 0.75))\n",
    "                    except KeyError:\n",
    "                        bin_iqr[var_name + 'q1'] = [np.nanquantile(bin_data[key], 0.25)]\n",
    "                        bin_iqr[var_name + 'q3'] = [np.nanquantile(bin_data[key], 0.75)]\n",
    "                else:\n",
    "                    try:\n",
    "                        bin_iqr[var_name + 'q1'].append(np.nan)\n",
    "                        bin_iqr[var_name + 'q3'].append(np.nan)\n",
    "                    except KeyError:\n",
    "                        bin_iqr[var_name + 'q1'] = [np.nan]\n",
    "                        bin_iqr[var_name + 'q3'] = [np.nan]\n",
    "    \n",
    "    #check if there is any data to plot\n",
    "    available_data = False\n",
    "    for value_list in value_lists:\n",
    "        for item in value_list:\n",
    "            if available_data == False:\n",
    "                if np.isnan(item) == False:\n",
    "                    available_data = True\n",
    "\n",
    "    #find values to serve as plot axis max and mins if there is data to plot\n",
    "    if available_data == True:\n",
    "        #x-axis on the main plot\n",
    "        all_quartiles = []\n",
    "        for key in bin_iqr:\n",
    "            all_quartiles += bin_iqr[key]\n",
    "        for key in bin_means:\n",
    "            if key != 'alt_bins':\n",
    "                all_quartiles += bin_means[key]\n",
    "        max_quartile = np.nanmax(all_quartiles)\n",
    "        min_quartile = np.nanmin(all_quartiles)\n",
    "        range_extension = (max_quartile - min_quartile) * 0.05\n",
    "        max_x = max_quartile + range_extension\n",
    "        min_x = min_quartile - range_extension\n",
    "        \n",
    "        #max value of the x-axis on the histogram plot\n",
    "        hist_max = np.nanmax(bin_count) * 1.05\n",
    "        \n",
    "        #y-axis on the plot\n",
    "        max_y = max(high_bin_edge)\n",
    "        min_y = min(low_bin_edge)\n",
    "\n",
    "    #if there is no data to plot, force the max and min values to the below values\n",
    "    elif available_data == False:\n",
    "        warn('Data provided does not contain any values to plot. Resulting plot will be empty.')\n",
    "        max_x = 1\n",
    "        min_x = 0\n",
    "        max_y = 12000\n",
    "        min_y = 0\n",
    "        hist_max = 1\n",
    "\n",
    "    \n",
    "    #create figure\n",
    "    fig = plot.figure()\n",
    "    fig.set_size_inches(6.4, 4.8)\n",
    "    \n",
    "    gs = gridspec.GridSpec(ncols = 2, nrows = 1, width_ratios = [1, 4], wspace = 0.05)\n",
    "    main_plot = fig.add_subplot(gs[1])\n",
    "    hist_plot = fig.add_subplot(gs[0])\n",
    "\n",
    "    #generate the main vertical plot\n",
    "    if title != None:\n",
    "        main_plot.set_title(title)\n",
    "    if x_label != None: \n",
    "        main_plot.set_xlabel(x_label)\n",
    "    main_plot.set_ylabel('Altitude [m ASL]')\n",
    "    main_plot.set_xlim((min_x, max_x))\n",
    "    main_plot.set_ylim((min_y, max_y))\n",
    "    main_plot.yaxis.tick_right()\n",
    "    main_plot.yaxis.set_label_position('right')\n",
    "    for i in range(len(var_names)):\n",
    "        main_plot.bar([-10], [-10], color = colors[i], label = var_names[i])    #This adds each variable to the legend with a color box instead of a color line. None of this appears in the final plot\n",
    "        main_plot.plot(bin_medians[var_names[i]], bin_centers, color = colors[i], zorder = i + 1)\n",
    "        main_plot.scatter(bin_medians[var_names[i]], bin_centers, color = colors[i], zorder = i + 1, s = 10)\n",
    "        main_plot.scatter(bin_means[var_names[i]], bin_centers, color = colors[i], zorder = i + 1, s = 30, marker = '+')\n",
    "        for n in range(len(bin_centers)):\n",
    "            main_plot.plot([bin_iqr[var_names[i] + 'q1'][n], bin_iqr[var_names[i] + 'q3'][n]], [bin_centers[n], bin_centers[n]], color = colors[i], zorder = i + 1)\n",
    "    main_plot.grid(zorder = 0)\n",
    "    main_plot.scatter([], [], color = 'k', label = 'Median')    #This adds the symbol for mean to the legend\n",
    "    main_plot.scatter([], [], color = 'k', marker = '+', label = 'Mean')    #this adds the symbol for median to the legend\n",
    "    main_plot.plot([], [], color = 'k', label = 'IQR')    #this adds the symbol for median to the legend\n",
    "    main_plot.legend(bbox_to_anchor = [1.53, 1.018])\n",
    "\n",
    "    #generate the histogram of data points per bin\n",
    "    hist_plot.set_xlabel('Values per\\nAltitude Bin')\n",
    "    hist_plot.set_ylabel('Altitude [m ASL]')\n",
    "    hist_plot.set_ylim((min_y, max_y))\n",
    "    hist_plot.set_xlim((0, hist_max))\n",
    "    hist_plot.grid()\n",
    "    hist_plot.barh(bin_centers, bin_count, height = bin_widths, color = 'cornflowerblue')\n",
    "\n",
    "    if save_fig != False:\n",
    "        plot.savefig(save_fig)\n",
    "    elif save_fig == False:\n",
    "        plot.show()\n",
    "    plot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3eb10c",
   "metadata": {},
   "source": [
    "### Spatial Comparison\n",
    "The purpose of `spatial_plot()` is to show the spatial distribution of CMAQ bias relative to AEROMMA observations.\n",
    "\n",
    "Parameters:  \n",
    "* `cmaq_df` (pandas.DataFrame) - Pandas data frame containing at least CMAQ latitude and longitude data.\n",
    "* `plot_values` (vector like) - An array of values to be plotted on a map.\n",
    "* `plot_type` (str) [Default: `'diff'`] - the type of plot you would like to make. The options are `'diff'` (for when plotting the difference between two arrays) and `'raw'` (for when plotting a normal set of values not representing a difference betwwen two arrays).\n",
    "* `plot_title` (str or NoneType) [Default: `None`] - If not `None`, the input string becomes the plot title\n",
    "* `colorbar_name` (str) [Default: `'viridis'`] - If the `plot_type` is set to `'raw'`, the colorbar can be changed to any [option provided by Matplotlib](https://matplotlib.org/stable/users/explain/colors/colormaps.html).\n",
    "* `fig_size` (tuple) [Default: `(10, 8)`] - Tuple that defines the figure size with the format (width, height)\n",
    "* `save_fig` (str or bool) [Default: `False`] - The full path and filename to save the figure to. If no string is provided, the resulting figure will not be saved as a file.\n",
    "\n",
    "Returns:\n",
    "* `None`. Instead, a plot is produced.\n",
    "\n",
    "Notes:\n",
    "* The difference values are spatially binned by CMAQ grid column. If there is more than one AEROMMA observation that falls within a grid column, they will be averaged together to produce one mean difference value, regardless of the time or alitude the observation was taken.\n",
    "* To prevent extreme values from skewing the colorbar on the resulting plot, the max and min values of the colorbar are set by the maximum magnitude of the 5 and 95 percentile values as opposed to the maximum magnitude value overall (The max and min color bar values always have the same magnitude so the center of the diverging colorbar is set as close to zero as possible). This means that there will likely be some points with a difference value beyond the range of the colorbar. However, these values should only represent 5-10% of the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e54e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_plot(cmaq_df, plot_values, plot_type = 'diff', plot_title = None, colorbar_name = 'viridis', fig_size = (10, 8), save_fig = False):\n",
    "    #force all plot values to be in np.ndarray format\n",
    "    plot_values = np.array(plot_values)\n",
    "    \n",
    "    #check to see if there is any valid data in plot_values\n",
    "    all_data_missing = True\n",
    "    for item in plot_values:\n",
    "        if np.isnan(item) == False:\n",
    "            all_data_missing = False\n",
    "\n",
    "    #warn the user if all values are missing\n",
    "    if all_data_missing == True:\n",
    "        warn('All AEROMMA data is missing. Resulting plot will be empty.')\n",
    "\n",
    "    elif all_data_missing == False:\n",
    "        #Create a DataFrame to hold the spatial data\n",
    "        spatial_df = pd.DataFrame()\n",
    "        spatial_df['coords'] = list(zip(cmaq_df['LON'], cmaq_df['LAT']))\n",
    "        spatial_df['flight_values'] = plot_values\n",
    "\n",
    "        #Create a list of unique coordinate pairs\n",
    "        unique_coords = list(set(spatial_df['coords']))\n",
    "\n",
    "        #find the average value for each coordinate pair\n",
    "        coord_values = []\n",
    "        for coord_pair in unique_coords:\n",
    "            coord_values.append(np.mean(spatial_df['flight_values'].loc[spatial_df['coords'] == coord_pair]))\n",
    "\n",
    "        #remove coord pairs and values where the value is NaN\n",
    "        spatial_df = pd.DataFrame({'coords': unique_coords, 'flight_values': coord_values})\n",
    "        spatial_df = spatial_df.loc[spatial_df['flight_values'].isnull() == False]\n",
    "\n",
    "        #add lats and lons back to the DataFrame separately\n",
    "        spatial_df['lons'] = [coord[0] for coord in spatial_df['coords']]\n",
    "        spatial_df['lats'] = [coord[1] for coord in spatial_df['coords']]\n",
    "\n",
    "        #find values to serve as plot axis max and mins\n",
    "        #find max and min lat and lon values\n",
    "        max_lat = spatial_df['lats'].max()\n",
    "        min_lat = spatial_df['lats'].min()\n",
    "        max_lon = spatial_df['lons'].max()\n",
    "        min_lon = spatial_df['lons'].min()\n",
    "\n",
    "        #find the range of lat and lon values\n",
    "        lat_range = max_lat - min_lat\n",
    "        lon_range = max_lon - min_lon\n",
    "\n",
    "        #find the range of lat and lon values in meters\n",
    "        lat_to_m = lat_range * 111320    #1 degree of latitude is approximately 111320 km\n",
    "        lon_to_m = lon_range * 111320 * np.cos((np.pi / 180) * ((lat_range / 2) + min_lat))    #distance in longitude varys with latitude. The calulation from above is multiplied by the cosine of the middle latitude to compensate\n",
    "        \n",
    "        #find the larger of the two distances\n",
    "        range_extender = 1.1    #this adds a buffer to the plot extent\n",
    "        max_range = max(lat_to_m * range_extender, lon_to_m * range_extender)\n",
    "\n",
    "        #find the max and min lat values to use for the plot extent\n",
    "        lat_center = max_lat - (lat_range / 2)\n",
    "        min_y_extent = lat_center - (max_range / 111320 / 2)    #this converts the max_range value back to degrees latitude and subracts half from the center latitude\n",
    "        max_y_extent = lat_center + (max_range / 111320 / 2)    #this converts the max_range value back to degrees latitude and adds half to the center latitude\n",
    "\n",
    "        #find the max and min lon values to use for the plot extent\n",
    "        lon_center = max_lon - (lon_range / 2)\n",
    "        min_x_extent = lon_center - (max_range / 111320 / np.cos((np.pi / 180) * ((lat_range / 2) + min_lat)) / 2)    #this converts the max_range value back to degrees longitude and subracts half from the center longitude\n",
    "        max_x_extent = lon_center + (max_range / 111320 / np.cos((np.pi / 180) * ((lat_range / 2) + min_lat)) / 2)    #this converts the max_range value back to degrees longitude and adds half to the center longitude\n",
    "\n",
    "        #find the max absolute value of the 5 and 95 precentile differences\n",
    "        #to set the color bar limits. The max and min values are not used \n",
    "        #because their magnitudes are sometimes much larger than all other\n",
    "        #values and would skew the color bar\n",
    "        value_05 = np.nanquantile(np.array(spatial_df['flight_values']), 0.05)\n",
    "        value_95 = np.nanquantile(np.array(spatial_df['flight_values']), 0.95)\n",
    "        max_quantile_extreme = max(abs(value_05), abs(value_95))\n",
    "\n",
    "\n",
    "    #create a figure to plot the data on\n",
    "    fig = plot.figure(figsize = fig_size)\n",
    "    fig.set_size_inches(10, 8)\n",
    "    ax = plot.axes(projection = ccrs.PlateCarree())\n",
    "    if plot_title != None:\n",
    "        ax.set_title(plot_title)\n",
    "\n",
    "    #add map features\n",
    "    ax.add_feature(cfeature.LAND, facecolor = 'floralwhite', zorder = 1)\n",
    "    ax.add_feature(cfeature.LAKES, facecolor = 'w', zorder = 2)\n",
    "    ax.add_feature(cfeature.OCEAN, facecolor = 'w', zorder = 2)\n",
    "    ax.add_feature(cfeature.STATES, edgecolor = 'k', zorder = 7)\n",
    "    ax.add_feature(cfeature.COASTLINE, edgecolor = 'k', zorder = 7)\n",
    "\n",
    "    #plot the data if there is any\n",
    "    if all_data_missing == False:\n",
    "        if plot_type == 'diff':\n",
    "            value_plot = ax.scatter(spatial_df['lons'], spatial_df['lats'], c = spatial_df['flight_values'], cmap = 'coolwarm', s = 10, zorder = 10, vmin = -1 * max_quantile_extreme, vmax = max_quantile_extreme)\n",
    "        if plot_type == 'raw':\n",
    "            value_plot = ax.scatter(spatial_df['lons'], spatial_df['lats'], c = spatial_df['flight_values'], cmap = colorbar_name, s = 10, zorder = 10, vmin = value_05, vmax = value_95)\n",
    "\n",
    "        ax.set_extent((min_x_extent, max_x_extent, min_y_extent, max_y_extent), crs = ccrs.PlateCarree())\n",
    "        plot.colorbar(value_plot, orientation = 'horizontal', pad = 0.05, shrink = 0.7, extend = 'both')\n",
    "\n",
    "    #is there is no data, constrain the map extent to the United States\n",
    "    elif all_data_missing == True:\n",
    "        ax.set_extent((-126, -66, 24, 50), crs = ccrs.PlateCarree())\n",
    "\n",
    "    if save_fig != False:\n",
    "        plot.savefig(save_fig)\n",
    "    elif save_fig == False:\n",
    "        plot.show()\n",
    "    plot.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1e9ff5",
   "metadata": {},
   "source": [
    "### Plot value relative to HCN\n",
    "The purpose of the `function_of_hcn()` function is to create a scatter plot that shows how a value changes with varying HCN. This is important when performing an analysis of wildfire smoke because it often has a much higher concentration of HCN than surrounding environments.\n",
    "\n",
    "Parameters:  \n",
    "* `hcn_values` (vector like) - a vector of hydrogen cyanide values corresponding to the values you would like to plot. Ideally, this vector should come from AEROMMA data since they are observations and will better represent when the real HCN values are high (likely cooresponding to wildfire smoke) as opposed to CMAQ which may not have an accurate forecast. CMAQ values can be used if desired though.\n",
    "* `plot_values` (vector_like) - a vector of values you would like to plot against the concentration of HCN to see if there is any separation of values at higher and lower HCN concentrations.\n",
    "* `hcn_units` (str) [Default: `'ppt'`] - The units of the HCN values plotted on the x-axis\n",
    "* `y_label` (str or NoneType) [Default: `None`] - The label on the y-axis of the plot\n",
    "* `title` (str or NoneType) [Default: `None`] - The title of the plot\n",
    "* `save_fig` (str or bool) [Default: `False`] - The full path and filename to save the figure to. If no string is provided, the resulting figure will not be saved as a file.\n",
    "\n",
    "Returns:\n",
    "* `None`. Instead, a plot is produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04150713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_of_hcn(hcn_values, plot_values, hcn_units = 'ppt', y_label = None, title = None, save_fig = False):\n",
    "    #Check to see if there are values to plot\n",
    "    no_hcn = True\n",
    "    for value in hcn_values:\n",
    "        if np.isnan(value) == False:\n",
    "            no_hcn = False\n",
    "    no_plot_values = True\n",
    "    for value in plot_values:\n",
    "        if np.isnan(value) == False:\n",
    "            no_plot_values = False\n",
    "    if no_hcn == True or no_plot_values == True:    \n",
    "        no_data = True\n",
    "        warn('Data provided does not contain any values to plot. Resulting plot will be empty.')\n",
    "    else:\n",
    "        no_data = False\n",
    "\n",
    "    #set values for max and min y-value\n",
    "    if no_data == False:\n",
    "        y_range = np.nanmax(plot_values) - np.nanmin(plot_values)\n",
    "        y_max = np.nanmax(plot_values) + y_range * 0.05\n",
    "        y_min = np.nanmin(plot_values) - y_range * 0.05\n",
    "\n",
    "        #remove times with missing data\n",
    "        points_df = pd.DataFrame({'x':hcn_values, 'y':plot_values})\n",
    "        points_df = points_df.loc[points_df.notna().all(axis = 1)]\n",
    "        \n",
    "        #calculate point density\n",
    "        points_array = np.vstack([np.array(points_df['x']), np.array(points_df['y'])])\n",
    "        density = sp_stat.gaussian_kde(points_array)(points_array)\n",
    "        \n",
    "    #plot figure\n",
    "    fig = plot.figure()\n",
    "    plot.title(title)\n",
    "    plot.xlabel('HCN Concentration [' + hcn_units + ']')\n",
    "    plot.ylabel(y_label)\n",
    "    if no_data == False:\n",
    "        plot.xlim((0, np.nanmax(hcn_values) * 1.05))\n",
    "        plot.ylim((y_min, y_max))\n",
    "        points = plot.scatter(points_df['x'], points_df['y'], c = density, cmap = 'plasma', s = 10, zorder = 1)\n",
    "        cbar = fig.colorbar(points, label = 'Point Density', ticks = [np.min(density), np.max(density)])\n",
    "        cbar.ax.set_yticklabels(['Low', 'High'])\n",
    "        plot.axhline(y = 0, color = 'k', zorder = 2)\n",
    "    if save_fig != False:\n",
    "        plot.savefig(save_fig)\n",
    "    elif save_fig == False:\n",
    "        plot.show()\n",
    "    plot.grid()\n",
    "    plot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9e6ee3-91a7-4013-86f4-5305883f9ff2",
   "metadata": {},
   "source": [
    "# Package Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ce9d1b-0b71-4504-b152-3c3828129cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     index_file_path = '/work/MOD3DEV/mpye/flight_pairing/AEROMMA_flight_CMAQ_indices.nc'\n",
    "#     cmaq_data_dir_path = '/work/MOD3DEV/has/2023cracmm_ages/runs/20241216demodata/data/output_CCTM_v55_intel23.2_2023_12US4'\n",
    "#     cmaq_output_type = 'METCRO3D'\n",
    "#     if cmaq_output_type == 'CONC':\n",
    "#         cmaq_output_vars = ['NO', 'HONO', 'O3']\n",
    "#     elif cmaq_output_type == 'METCRO3D':\n",
    "#         cmaq_output_vars = ['TA', 'PRES']\n",
    "    \n",
    "#     flight_output_vars = ['T', 'P']\n",
    "#     flight_data_dir = '/work/MOD3DEV/mpye/flight_pairing/flight_data/'\n",
    "    \n",
    "#     for dir_name in sorted(os.listdir(flight_data_dir))[-18:]:\n",
    "#         if 'AEROMMA' in dir_name:\n",
    "#             mrg_file_path = flight_data_dir + dir_name + '/' + dir_name + '.csv'\n",
    "#             sec_data = extract_flight_data(mrg_file_path, output_vars = flight_output_vars)\n",
    "#             clean_sec_data = rm_1hz_negatives(sec_data)\n",
    "#             flight_df = time_agg_data(clean_sec_data)\n",
    "\n",
    "#             flight_id = flight_id_creator(mrg_file_path)\n",
    "#             cmaq_df = cmaq_flight_pairing.extract_cmaq_flight_data(flight_id, index_file_path, cmaq_data_dir_path, output_vars = cmaq_output_vars, cmaq_output_type = cmaq_output_type)\n",
    "#             cmaq_df, flight_df = rm_outside_model_times(cmaq_df, flight_df)\n",
    "\n",
    "#             stats_table(cmaq_df['TA'], flight_df['T'] / 100, 'Temperature', 'K') \n",
    "#             #time_series(cmaq_df.index, [cmaq_df['TA'], flight_df['T'] / 100], ['CMAQ', 'AEROMMA'], colors = ['r', 'k'])                      \n",
    "#             #spatial_df = spatial_diff_plot(cmaq_df, cmaq_df['TA'], flight_df['T'] / 100, flight_id + '\\nCMAQ minus AEROMMA Temperature [K]')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flight_env_kernel",
   "language": "python",
   "name": "flight_env_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
